# VibeNear - Robots.txt
# This file tells search engines which parts of our website they can crawl

# Allow all crawlers
User-agent: *

# Allow crawling of main content
Allow: /
Allow: /how-it-works
Allow: /why-vibe-near
Allow: /for-businesses
Allow: /for-students
Allow: /faqs
Allow: /our-apps
Allow: /privacy_policy

# Disallow crawling of sensitive areas
Disallow: /api/
Disallow: /_next/
Disallow: /admin/
Disallow: /test/
Disallow: /temp/
Disallow: /draft/

# Disallow crawling of file directories
Disallow: /files/
Disallow: /animations/
Disallow: /images/

# Disallow crawling of development files
Disallow: /*.json$
Disallow: /*.xml$
Disallow: /*.txt$

# Crawl delay (optional - be respectful to servers)
Crawl-delay: 1

# Sitemap location (when you create one)
Sitemap: https://vibenear.com/sitemap.xml

# Additional rules for specific bots
User-agent: Googlebot
Allow: /

User-agent: Bingbot
Allow: /

User-agent: Slurp
Allow: /

# Block aggressive scrapers
User-agent: AhrefsBot
Disallow: /

User-agent: SemrushBot
Disallow: /

User-agent: MJ12bot
Disallow: /

# Block AI training bots (optional)
User-agent: GPTBot
Disallow: /

User-agent: ChatGPT-User
Disallow: /

User-agent: CCBot
Disallow: /

# Block archive bots
User-agent: ia_archiver
Disallow: /

User-agent: archive.org_bot
Disallow: /
